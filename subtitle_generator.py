#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Module t·∫°o ph·ª• ƒë·ªÅ t·ª´ audio s·ª≠ d·ª•ng Speech-to-Text
"""

import os
import tempfile
import subprocess
from pathlib import Path

try:
    import speech_recognition as sr
    import pydub
    from pydub import AudioSegment
    import wave
    HAS_SPEECH_RECOGNITION = True
except ImportError:
    HAS_SPEECH_RECOGNITION = False

try:
    import whisper
    HAS_WHISPER = True
except ImportError:
    HAS_WHISPER = False

class SubtitleGenerator:
    def __init__(self):
        self.recognizer = None
        self.whisper_model = None
        
        # ∆Øu ti√™n s·ª≠ d·ª•ng Whisper n·∫øu c√≥
        if HAS_WHISPER:
            print("ü§ñ S·ª≠ d·ª•ng OpenAI Whisper ƒë·ªÉ t·∫°o ph·ª• ƒë·ªÅ")
            try:
                self.whisper_model = whisper.load_model("base")
            except Exception as e:
                print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫£i Whisper model: {e}")
                self.whisper_model = None
        
        if HAS_SPEECH_RECOGNITION and not self.whisper_model:
            print("üéôÔ∏è S·ª≠ d·ª•ng SpeechRecognition ƒë·ªÉ t·∫°o ph·ª• ƒë·ªÅ")
            self.recognizer = sr.Recognizer()
        
        if not HAS_WHISPER and not HAS_SPEECH_RECOGNITION:
            raise ImportError(
                "C·∫ßn c√†i ƒë·∫∑t √≠t nh·∫•t m·ªôt trong c√°c th∆∞ vi·ªán: "
                "openai-whisper ho·∫∑c SpeechRecognition"
            )
    
    def generate_subtitle(self, audio_path, subtitle_output_path, language='vi', words_per_line=7):
        """
        T·∫°o ph·ª• ƒë·ªÅ t·ª´ file audio
        
        Args:
            audio_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file audio
            subtitle_output_path (str): ƒê∆∞·ªùng d·∫´n l∆∞u file ph·ª• ƒë·ªÅ .srt
            language (str): M√£ ng√¥n ng·ªØ (vi, en, etc.)        """
        if self.whisper_model:            self._generate_with_whisper(audio_path, subtitle_output_path, language, words_per_line)
        elif self.recognizer:
            self._generate_with_speech_recognition(audio_path, subtitle_output_path, language, words_per_line)
        else:
            raise Exception("Kh√¥ng c√≥ engine n√†o ƒë·ªÉ t·∫°o ph·ª• ƒë·ªÅ")
    
    def _generate_with_whisper(self, audio_path, subtitle_output_path, language, words_per_line=7):
        """T·∫°o ph·ª• ƒë·ªÅ s·ª≠ d·ª•ng OpenAI Whisper"""
        try:
            print("ü§ñ ƒêang t·∫°o ph·ª• ƒë·ªÅ v·ªõi Whisper...")
            
            # Ki·ªÉm tra file audio c√≥ t·ªìn t·∫°i v√† c√≥ n·ªôi dung kh√¥ng
            if not os.path.exists(audio_path):
                raise Exception(f"File audio kh√¥ng t·ªìn t·∫°i: {audio_path}")
            
            # Ki·ªÉm tra k√≠ch th∆∞·ªõc file audio
            audio_size = os.path.getsize(audio_path)
            if audio_size < 1024:  # File qu√° nh·ªè (< 1KB)
                print("‚ö†Ô∏è File audio tr·ªëng ho·∫∑c qu√° nh·ªè, t·∫°o ph·ª• ƒë·ªÅ m·∫∑c ƒë·ªãnh...")
                self._create_default_subtitle(subtitle_output_path)
                return
            
            # Whisper x·ª≠ l√Ω tr·ª±c ti·∫øp file audio
            result = self.whisper_model.transcribe(
                audio_path, 
                language=language if language != 'vi' else 'vietnamese'
            )
            
            # Ki·ªÉm tra k·∫øt qu·∫£
            if not result.get('segments') or len(result['segments']) == 0:
                print("‚ö†Ô∏è Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c gi·ªçng n√≥i, t·∫°o ph·ª• ƒë·ªÅ m·∫∑c ƒë·ªãnh...")
                self._create_default_subtitle(subtitle_output_path)
                return
            
            # Chuy·ªÉn ƒë·ªïi k·∫øt qu·∫£ th√†nh format SRT
            srt_content = self._whisper_result_to_srt(result, words_per_line)
            
            # L∆∞u file SRT
            with open(subtitle_output_path, 'w', encoding='utf-8') as f:
                f.write(srt_content)
            
            print(f"‚úÖ T·∫°o ph·ª• ƒë·ªÅ th√†nh c√¥ng v·ªõi {len(result['segments'])} ƒëo·∫°n")
            
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói t·∫°o ph·ª• ƒë·ªÅ v·ªõi Whisper: {str(e)}, t·∫°o ph·ª• ƒë·ªÅ m·∫∑c ƒë·ªãnh...")
            try:
                self._create_default_subtitle(subtitle_output_path)
            except Exception as e2:
                raise Exception(f"Kh√¥ng th·ªÉ t·∫°o ph·ª• ƒë·ªÅ: {str(e2)}")
    
    def _create_default_subtitle(self, subtitle_output_path):
        """T·∫°o ph·ª• ƒë·ªÅ m·∫∑c ƒë·ªãnh cho video kh√¥ng c√≥ audio"""
        default_srt = """1
00:00:01,000 --> 00:00:05,000
[Video kh√¥ng c√≥ √¢m thanh]

2
00:00:06,000 --> 00:00:10,000
[No audio detected]
"""
        
        with open(subtitle_output_path, 'w', encoding='utf-8') as f:
            f.write(default_srt)
        
        print(f"‚úÖ T·∫°o ph·ª• ƒë·ªÅ m·∫∑c ƒë·ªãnh: {subtitle_output_path}")
    
    def _whisper_result_to_srt(self, result, words_per_line=7):
        """Chuy·ªÉn ƒë·ªïi k·∫øt qu·∫£ Whisper th√†nh format SRT v·ªõi gi·ªõi h·∫°n t·ª´ m·ªói d√≤ng"""
        srt_content = ""
        subtitle_index = 1
        
        for segment in result['segments']:
            start_time = segment['start']
            end_time = segment['end']
            text = segment['text'].strip()
            
            # Chia text th√†nh c√°c d√≤ng ng·∫Øn v·ªõi s·ªë t·ª´ t√πy ch·ªânh
            lines = self._split_text_into_lines(text, max_words_per_line=words_per_line)
            
            if not lines:
                continue
                
            # T√≠nh th·ªùi gian cho m·ªói d√≤ng
            segment_duration = end_time - start_time
            time_per_line = segment_duration / len(lines)
            
            for i, line in enumerate(lines):
                line_start = start_time + (i * time_per_line)
                line_end = start_time + ((i + 1) * time_per_line)
                
                srt_start_time = self._seconds_to_srt_time(line_start)
                srt_end_time = self._seconds_to_srt_time(line_end)
                
                srt_content += f"{subtitle_index}\n"
                srt_content += f"{srt_start_time} --> {srt_end_time}\n"
                srt_content += f"{line}\n\n"
                
                subtitle_index += 1
        
        return srt_content
    
    def _generate_with_speech_recognition(self, audio_path, subtitle_output_path, language, words_per_line=7):
        """T·∫°o ph·ª• ƒë·ªÅ s·ª≠ d·ª•ng SpeechRecognition (ph∆∞∆°ng ph√°p d·ª± ph√≤ng)"""
        try:
            print("üéôÔ∏è ƒêang t·∫°o ph·ª• ƒë·ªÅ v·ªõi SpeechRecognition...")
            
            # Chuy·ªÉn ƒë·ªïi audio th√†nh wav n·∫øu c·∫ßn
            audio = AudioSegment.from_file(audio_path)
            
            # Chia audio th√†nh c√°c ƒëo·∫°n nh·ªè (30 gi√¢y m·ªói ƒëo·∫°n)
            chunk_length_ms = 30000  # 30 seconds
            chunks = [audio[i:i + chunk_length_ms] 
                     for i in range(0, len(audio), chunk_length_ms)]
            
            srt_content = ""
            
            for i, chunk in enumerate(chunks):
                try:
                    # L∆∞u chunk t·∫°m th·ªùi
                    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
                        chunk.export(temp_file.name, format="wav")
                        
                        # Nh·∫≠n d·∫°ng gi·ªçng n√≥i
                        with sr.AudioFile(temp_file.name) as source:
                            audio_data = self.recognizer.record(source)
                            
                        # Ch·ªçn engine d·ª±a tr√™n ng√¥n ng·ªØ
                        if language == 'vi':
                            text = self.recognizer.recognize_google(
                                audio_data, language='vi-VN'
                            )
                        else:
                            text = self.recognizer.recognize_google(
                                audio_data, language=language
                            )
                          # T√≠nh to√°n th·ªùi gian
                        start_seconds = i * 30
                        end_seconds = min((i + 1) * 30, len(audio) / 1000)
                          # Chia text th√†nh c√°c d√≤ng ng·∫Øn v·ªõi s·ªë t·ª´ t√πy ch·ªânh
                        lines = self._split_text_into_lines(text, max_words_per_line=words_per_line)
                        
                        if lines:
                            # Ph√¢n b·ªï th·ªùi gian cho t·ª´ng d√≤ng
                            segment_duration = end_seconds - start_seconds
                            time_per_line = segment_duration / len(lines)
                            
                            for j, line in enumerate(lines):
                                line_start = start_seconds + (j * time_per_line)
                                line_end = start_seconds + ((j + 1) * time_per_line)
                                
                                line_start_time = self._seconds_to_srt_time(line_start)
                                line_end_time = self._seconds_to_srt_time(line_end)
                                
                                # Th√™m v√†o n·ªôi dung SRT v·ªõi index li√™n t·ª•c
                                subtitle_count = len([x for x in srt_content.split('\n\n') if x.strip()]) + 1
                                srt_content += f"{subtitle_count}\n"
                                srt_content += f"{line_start_time} --> {line_end_time}\n"
                                srt_content += f"{line}\n\n"
                        
                        # X√≥a file t·∫°m
                        os.unlink(temp_file.name)
                        
                except sr.UnknownValueError:
                    # B·ªè qua ƒëo·∫°n kh√¥ng nh·∫≠n d·∫°ng ƒë∆∞·ª£c
                    continue
                except Exception as e:
                    print(f"‚ö†Ô∏è L·ªói x·ª≠ l√Ω ƒëo·∫°n {i}: {e}")
                    continue
            
            # L∆∞u file SRT
            with open(subtitle_output_path, 'w', encoding='utf-8') as f:
                f.write(srt_content)
            
            print(f"‚úÖ T·∫°o ph·ª• ƒë·ªÅ th√†nh c√¥ng v·ªõi {len(chunks)} ƒëo·∫°n")
            
        except Exception as e:
            raise Exception(f"L·ªói t·∫°o ph·ª• ƒë·ªÅ v·ªõi SpeechRecognition: {str(e)}")
    
    def _seconds_to_srt_time(self, seconds):
        """Chuy·ªÉn ƒë·ªïi gi√¢y th√†nh ƒë·ªãnh d·∫°ng th·ªùi gian SRT (HH:MM:SS,mmm)"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        milliseconds = int((seconds % 1) * 1000)
        
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{milliseconds:03d}"
    
    def _split_text_into_lines(self, text, max_words_per_line=7):
        """Chia text th√†nh c√°c d√≤ng ng·∫Øn v·ªõi t·ªëi ƒëa s·ªë t·ª´ cho tr∆∞·ªõc"""
        import re
        
        # L√†m s·∫°ch text
        text = text.strip()
        if not text:
            return []
        
        # T√°ch th√†nh t·ª´ng t·ª´
        words = re.findall(r'\S+', text)
        
        if not words:
            return []
        
        lines = []
        current_line = []
        
        for word in words:
            current_line.append(word)
            
            # N·∫øu ƒë·∫°t gi·ªõi h·∫°n t·ª´ ho·∫∑c g·∫∑p d·∫•u c√¢u, t·∫°o d√≤ng m·ªõi
            if (len(current_line) >= max_words_per_line or 
                word.endswith(('.', '!', '?', ',', ';'))):
                
                lines.append(' '.join(current_line))
                current_line = []
        
        # Th√™m d√≤ng cu·ªëi n·∫øu c√≤n t·ª´
        if current_line:
            lines.append(' '.join(current_line))
        
        return lines
    
    def _optimize_subtitle_timing(self, lines, total_duration):
        """T·ªëi ∆∞u th·ªùi gian hi·ªÉn th·ªã cho t·ª´ng d√≤ng ph·ª• ƒë·ªÅ"""
        if not lines:
            return []
        
        # T√≠nh to√°n th·ªùi gian d·ª±a tr√™n ƒë·ªô d√†i text
        line_weights = []
        total_chars = 0
        
        for line in lines:
            char_count = len(line)
            line_weights.append(char_count)
            total_chars += char_count
        
        # Ph√¢n b·ªï th·ªùi gian theo t·ª∑ l·ªá
        timings = []
        current_time = 0
        
        for weight in line_weights:
            if total_chars > 0:
                duration = (weight / total_chars) * total_duration
                # ƒê·∫£m b·∫£o th·ªùi gian t·ªëi thi·ªÉu 1 gi√¢y, t·ªëi ƒëa 4 gi√¢y
                duration = max(1.0, min(4.0, duration))
            else:
                duration = total_duration / len(lines)
            
            timings.append({
                'start': current_time,
                'end': current_time + duration,
                'duration': duration
            })
            
            current_time += duration
        
        return timings
