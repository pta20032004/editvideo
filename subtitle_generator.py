#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Module t·∫°o ph·ª• ƒë·ªÅ t·ª´ audio s·ª≠ d·ª•ng Speech-to-Text
"""

import os
import tempfile
import subprocess
from pathlib import Path

try:
    import speech_recognition as sr
    import pydub
    from pydub import AudioSegment
    import wave
    HAS_SPEECH_RECOGNITION = True
except ImportError:
    HAS_SPEECH_RECOGNITION = False

try:
    import whisper
    HAS_WHISPER = True
except ImportError:
    HAS_WHISPER = False

class SubtitleGenerator:
    def __init__(self):
        self.recognizer = None
        self.whisper_model = None
        
        # ‚úÖ TH√äM: H·ªó tr·ª£ ti·∫øng Trung t·ªët h∆°n
        self.language_codes = {
            'vi': 'vietnamese',
            'en': 'english', 
            'zh': 'chinese',        # ‚úÖ TH√äM
            'zh-cn': 'chinese',     # ‚úÖ TH√äM: Simplified Chinese
            'zh-tw': 'chinese',     # ‚úÖ TH√äM: Traditional Chinese
            'ja': 'japanese',
            'ko': 'korean',
            'es': 'spanish',
            'fr': 'french',
            'de': 'german'
        }
        
        if HAS_WHISPER:
            print("ü§ñ S·ª≠ d·ª•ng OpenAI Whisper ƒë·ªÉ t·∫°o ph·ª• ƒë·ªÅ")
            try:
                # ‚úÖ S·ª¨A: S·ª≠ d·ª•ng model l·ªõn h∆°n cho ti·∫øng Trung
                self.whisper_model = whisper.load_model("base")  # C√≥ th·ªÉ ƒë·ªïi th√†nh "small" ho·∫∑c "medium"
            except Exception as e:
                print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫£i Whisper model: {e}")
                self.whisper_model = None
    
    def generate_subtitle(self, audio_path, subtitle_output_path, language='vi', words_per_line=7):
        """
        T·∫°o ph·ª• ƒë·ªÅ t·ª´ file audio
        
        Args:
            audio_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file audio
            subtitle_output_path (str): ƒê∆∞·ªùng d·∫´n l∆∞u file ph·ª• ƒë·ªÅ .srt
            language (str): M√£ ng√¥n ng·ªØ (vi, en, etc.)        """
        if self.whisper_model:            self._generate_with_whisper(audio_path, subtitle_output_path, language, words_per_line)
        elif self.recognizer:
            self._generate_with_speech_recognition(audio_path, subtitle_output_path, language, words_per_line)
        else:
            raise Exception("Kh√¥ng c√≥ engine n√†o ƒë·ªÉ t·∫°o ph·ª• ƒë·ªÅ")
    
    def _generate_with_whisper(self, audio_path, subtitle_output_path, language, words_per_line=7):
        """T·∫°o ph·ª• ƒë·ªÅ s·ª≠ d·ª•ng OpenAI Whisper - C·∫¨P NH·∫¨T TI·∫æNG TRUNG"""
        try:
            print("ü§ñ ƒêang t·∫°o ph·ª• ƒë·ªÅ v·ªõi Whisper...")
            
            if not os.path.exists(audio_path):
                raise Exception(f"File audio kh√¥ng t·ªìn t·∫°i: {audio_path}")
            
            audio_size = os.path.getsize(audio_path)
            if audio_size < 1024:
                print("‚ö†Ô∏è File audio tr·ªëng ho·∫∑c qu√° nh·ªè, t·∫°o ph·ª• ƒë·ªÅ m·∫∑c ƒë·ªãnh...")
                self._create_default_subtitle(subtitle_output_path)
                return
            
            # ‚úÖ S·ª¨A: X·ª≠ l√Ω ng√¥n ng·ªØ ti·∫øng Trung ƒë·∫∑c bi·ªát
            whisper_language = None
            if language in self.language_codes:
                whisper_language = self.language_codes[language]
            elif language.startswith('zh'):  # zh, zh-cn, zh-tw
                whisper_language = 'chinese'
            else:
                whisper_language = language  # Fallback
            
            print(f"üåê S·ª≠ d·ª•ng Whisper language: {whisper_language} cho input: {language}")
            
            # ‚úÖ TH√äM: T√πy ch·ªçn ƒë·∫∑c bi·ªát cho ti·∫øng Trung
            transcribe_options = {
                'language': whisper_language,
                'task': 'transcribe',  # Kh√¥ng d·ªãch, ch·ªâ transcribe
            }
            
            # ‚úÖ TH√äM: Th√™m temperature cho ti·∫øng Trung ƒë·ªÉ c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c
            if language.startswith('zh'):
                transcribe_options['temperature'] = 0.0  # Deterministic cho ti·∫øng Trung
                transcribe_options['beam_size'] = 5      # TƒÉng beam size
                
            result = self.whisper_model.transcribe(audio_path, **transcribe_options)
            
            if not result.get('segments') or len(result['segments']) == 0:
                print("‚ö†Ô∏è Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c gi·ªçng n√≥i, t·∫°o ph·ª• ƒë·ªÅ m·∫∑c ƒë·ªãnh...")
                self._create_default_subtitle(subtitle_output_path)
                return
            
            # ‚úÖ S·ª¨A: Chuy·ªÉn ƒë·ªïi k·∫øt qu·∫£ th√†nh format SRT v·ªõi x·ª≠ l√Ω ti·∫øng Trung
            srt_content = self._whisper_result_to_srt(result, words_per_line, language)
            
            # ‚úÖ TH√äM: ƒê·∫£m b·∫£o encoding UTF-8 cho ti·∫øng Trung
            with open(subtitle_output_path, 'w', encoding='utf-8', errors='ignore') as f:
                f.write(srt_content)
            
            print(f"‚úÖ T·∫°o ph·ª• ƒë·ªÅ {language} th√†nh c√¥ng v·ªõi {len(result['segments'])} ƒëo·∫°n")
            
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói t·∫°o ph·ª• ƒë·ªÅ v·ªõi Whisper: {str(e)}, t·∫°o ph·ª• ƒë·ªÅ m·∫∑c ƒë·ªãnh...")
            try:
                self._create_default_subtitle(subtitle_output_path)
            except Exception as e2:
                raise Exception(f"Kh√¥ng th·ªÉ t·∫°o ph·ª• ƒë·ªÅ: {str(e2)}")
    
    def _create_default_subtitle(self, subtitle_output_path):
        """T·∫°o ph·ª• ƒë·ªÅ m·∫∑c ƒë·ªãnh cho video kh√¥ng c√≥ audio"""
        default_srt = """1
00:00:01,000 --> 00:00:05,000
[Video kh√¥ng c√≥ √¢m thanh]

2
00:00:06,000 --> 00:00:10,000
[No audio detected]
"""
        
        with open(subtitle_output_path, 'w', encoding='utf-8') as f:
            f.write(default_srt)
        
        print(f"‚úÖ T·∫°o ph·ª• ƒë·ªÅ m·∫∑c ƒë·ªãnh: {subtitle_output_path}")
    
    def _whisper_result_to_srt(self, result, words_per_line=7, language='vi'):
        """Chuy·ªÉn ƒë·ªïi k·∫øt qu·∫£ Whisper th√†nh format SRT - C·∫¨P NH·∫¨T TI·∫æNG TRUNG"""
        srt_content = ""
        subtitle_index = 1
        
        for segment in result['segments']:
            start_time = segment['start']
            end_time = segment['end']
            text = segment['text'].strip()
            
            # ‚úÖ TH√äM: X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho ti·∫øng Trung (kh√¥ng c√≥ kho·∫£ng tr·∫Øng gi·ªØa t·ª´)
            if language.startswith('zh'):
                lines = self._split_chinese_text_into_lines(text, max_chars_per_line=words_per_line*2)
            else:
                lines = self._split_text_into_lines(text, max_words_per_line=words_per_line)
            
            if not lines:
                continue
                
            # T√≠nh th·ªùi gian cho m·ªói d√≤ng
            segment_duration = end_time - start_time
            time_per_line = segment_duration / len(lines)
            
            for i, line in enumerate(lines):
                line_start = start_time + (i * time_per_line)
                line_end = start_time + ((i + 1) * time_per_line)
                
                srt_start_time = self._seconds_to_srt_time(line_start)
                srt_end_time = self._seconds_to_srt_time(line_end)
                
                srt_content += f"{subtitle_index}\n"
                srt_content += f"{srt_start_time} --> {srt_end_time}\n"
                srt_content += f"{line}\n\n"
                
                subtitle_index += 1
        
        return srt_content

    def _generate_with_speech_recognition(self, audio_path, subtitle_output_path, language, words_per_line=7):
        """T·∫°o ph·ª• ƒë·ªÅ s·ª≠ d·ª•ng SpeechRecognition (ph∆∞∆°ng ph√°p d·ª± ph√≤ng)"""
        try:
            print("üéôÔ∏è ƒêang t·∫°o ph·ª• ƒë·ªÅ v·ªõi SpeechRecognition...")
            
            # Chuy·ªÉn ƒë·ªïi audio th√†nh wav n·∫øu c·∫ßn
            audio = AudioSegment.from_file(audio_path)
            
            # Chia audio th√†nh c√°c ƒëo·∫°n nh·ªè (30 gi√¢y m·ªói ƒëo·∫°n)
            chunk_length_ms = 30000  # 30 seconds
            chunks = [audio[i:i + chunk_length_ms] 
                     for i in range(0, len(audio), chunk_length_ms)]
            
            srt_content = ""
            
            for i, chunk in enumerate(chunks):
                try:
                    # L∆∞u chunk t·∫°m th·ªùi
                    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
                        chunk.export(temp_file.name, format="wav")
                        
                        # Nh·∫≠n d·∫°ng gi·ªçng n√≥i
                        with sr.AudioFile(temp_file.name) as source:
                            audio_data = self.recognizer.record(source)
                            
                        # Ch·ªçn engine d·ª±a tr√™n ng√¥n ng·ªØ
                        if language == 'vi':
                            text = self.recognizer.recognize_google(
                                audio_data, language='vi-VN'
                            )
                        else:
                            text = self.recognizer.recognize_google(
                                audio_data, language=language
                            )
                          # T√≠nh to√°n th·ªùi gian
                        start_seconds = i * 30
                        end_seconds = min((i + 1) * 30, len(audio) / 1000)
                          # Chia text th√†nh c√°c d√≤ng ng·∫Øn v·ªõi s·ªë t·ª´ t√πy ch·ªânh
                        lines = self._split_text_into_lines(text, max_words_per_line=words_per_line)
                        
                        if lines:
                            # Ph√¢n b·ªï th·ªùi gian cho t·ª´ng d√≤ng
                            segment_duration = end_seconds - start_seconds
                            time_per_line = segment_duration / len(lines)
                            
                            for j, line in enumerate(lines):
                                line_start = start_seconds + (j * time_per_line)
                                line_end = start_seconds + ((j + 1) * time_per_line)
                                
                                line_start_time = self._seconds_to_srt_time(line_start)
                                line_end_time = self._seconds_to_srt_time(line_end)
                                
                                # Th√™m v√†o n·ªôi dung SRT v·ªõi index li√™n t·ª•c
                                subtitle_count = len([x for x in srt_content.split('\n\n') if x.strip()]) + 1
                                srt_content += f"{subtitle_count}\n"
                                srt_content += f"{line_start_time} --> {line_end_time}\n"
                                srt_content += f"{line}\n\n"
                        
                        # X√≥a file t·∫°m
                        os.unlink(temp_file.name)
                        
                except sr.UnknownValueError:
                    # B·ªè qua ƒëo·∫°n kh√¥ng nh·∫≠n d·∫°ng ƒë∆∞·ª£c
                    continue
                except Exception as e:
                    print(f"‚ö†Ô∏è L·ªói x·ª≠ l√Ω ƒëo·∫°n {i}: {e}")
                    continue
            
            # L∆∞u file SRT
            with open(subtitle_output_path, 'w', encoding='utf-8') as f:
                f.write(srt_content)
            
            print(f"‚úÖ T·∫°o ph·ª• ƒë·ªÅ th√†nh c√¥ng v·ªõi {len(chunks)} ƒëo·∫°n")
            
        except Exception as e:
            raise Exception(f"L·ªói t·∫°o ph·ª• ƒë·ªÅ v·ªõi SpeechRecognition: {str(e)}")
    
    def _seconds_to_srt_time(self, seconds):
        """Chuy·ªÉn ƒë·ªïi gi√¢y th√†nh ƒë·ªãnh d·∫°ng th·ªùi gian SRT (HH:MM:SS,mmm)"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        milliseconds = int((seconds % 1) * 1000)
        
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{milliseconds:03d}"
    
    def _split_text_into_lines(self, text, max_words_per_line=7):
        """Chia text th√†nh c√°c d√≤ng ng·∫Øn v·ªõi t·ªëi ƒëa s·ªë t·ª´ cho tr∆∞·ªõc"""
        import re
        
        # L√†m s·∫°ch text
        text = text.strip()
        if not text:
            return []
        
        # T√°ch th√†nh t·ª´ng t·ª´
        words = re.findall(r'\S+', text)
        
        if not words:
            return []
        
        lines = []
        current_line = []
        
        for word in words:
            current_line.append(word)
            
            # N·∫øu ƒë·∫°t gi·ªõi h·∫°n t·ª´ ho·∫∑c g·∫∑p d·∫•u c√¢u, t·∫°o d√≤ng m·ªõi
            if (len(current_line) >= max_words_per_line or 
                word.endswith(('.', '!', '?', ',', ';'))):
                
                lines.append(' '.join(current_line))
                current_line = []
        
        # Th√™m d√≤ng cu·ªëi n·∫øu c√≤n t·ª´
        if current_line:
            lines.append(' '.join(current_line))
        
        return lines
    
    def _split_chinese_text_into_lines(self, text, max_chars_per_line=14):
        """Chia text ti·∫øng Trung th√†nh c√°c d√≤ng ng·∫Øn theo s·ªë k√Ω t·ª±"""
        import re
        
        text = text.strip()
        if not text:
            return []
        
        # Chia theo d·∫•u c√¢u ti·∫øng Trung
        sentences = re.split(r'[„ÄÇÔºÅÔºüÔºõÔºå]', text)
        lines = []
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
                
            # N·∫øu c√¢u qu√° d√†i, chia nh·ªè theo s·ªë k√Ω t·ª±
            while len(sentence) > max_chars_per_line:
                # T√¨m v·ªã tr√≠ chia t·ªët nh·∫•t (∆∞u ti√™n sau d·∫•u ph·∫©y ho·∫∑c kho·∫£ng tr·∫Øng)
                split_pos = max_chars_per_line
                for i in range(max_chars_per_line-1, max_chars_per_line//2, -1):
                    if i < len(sentence) and sentence[i] in 'Ôºå„ÄÅ ':
                        split_pos = i + 1
                        break
                
                lines.append(sentence[:split_pos].strip())
                sentence = sentence[split_pos:].strip()
            
            if sentence:
                lines.append(sentence)
        
        return lines

    def _optimize_subtitle_timing(self, lines, total_duration):
        """T·ªëi ∆∞u th·ªùi gian hi·ªÉn th·ªã cho t·ª´ng d√≤ng ph·ª• ƒë·ªÅ"""
        if not lines:
            return []
        
        # T√≠nh to√°n th·ªùi gian d·ª±a tr√™n ƒë·ªô d√†i text
        line_weights = []
        total_chars = 0
        
        for line in lines:
            char_count = len(line)
            line_weights.append(char_count)
            total_chars += char_count
        
        # Ph√¢n b·ªï th·ªùi gian theo t·ª∑ l·ªá
        timings = []
        current_time = 0
        
        for weight in line_weights:
            if total_chars > 0:
                duration = (weight / total_chars) * total_duration
                # ƒê·∫£m b·∫£o th·ªùi gian t·ªëi thi·ªÉu 1 gi√¢y, t·ªëi ƒëa 4 gi√¢y
                duration = max(1.0, min(4.0, duration))
            else:
                duration = total_duration / len(lines)
            
            timings.append({
                'start': current_time,
                'end': current_time + duration,
                'duration': duration
            })
            
            current_time += duration
        
        return timings
